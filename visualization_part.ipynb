{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"ul8ooBUWoHVT","executionInfo":{"status":"ok","timestamp":1646957667307,"user_tz":480,"elapsed":5581,"user":{"displayName":"Joyce Huang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi26aQudjNxl3TwifJJnKZKg9OULnp--X1U8tKRIw=s64","userId":"04205349756726206625"}},"outputId":"01d2d7b0-cc83-4654-e0e4-ad7831847243","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":1}],"source":["import pandas as pd\n","import plotly.express as px\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from sklearn.decomposition import PCA\n","from sklearn.preprocessing import StandardScaler\n","import nltk\n","from wordcloud import WordCloud, STOPWORDS\n","from sklearn.cluster import KMeans\n","from sklearn.metrics import silhouette_samples, silhouette_score\n","nltk.download('punkt')\n","nltk.download('averaged_perceptron_tagger')"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"F5i2YFABU3s4","executionInfo":{"status":"ok","timestamp":1646957688428,"user_tz":480,"elapsed":21129,"user":{"displayName":"Joyce Huang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi26aQudjNxl3TwifJJnKZKg9OULnp--X1U8tKRIw=s64","userId":"04205349756726206625"}},"outputId":"47ab2e91-7cf1-442e-efd0-7cbbdbf28db4","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","data = \"/content/drive/Shared drives/ece143_proj/data_cleaned.csv\"\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RiPd8LMymH8Y","outputId":"97d33db6-c6d1-4df2-ebbe-cc57132701e1","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["#need origional df\n","from google.colab import drive\n","drive.mount('/content/drive')\n","ROOT_DIR = \"/content/drive/Shared drives/ece143_proj\"\n","txt_path = '/data.csv'\n","df_initial = pd.read_csv(ROOT_DIR+txt_path,encoding = \"ISO-8859-1\",dtype={'InvoiceID':str,'CustomerID':str})"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AtuST0Njk_-p"},"outputs":[],"source":["#exploring content of variables\n","df_initial['InvoiceDate'] = pd.to_datetime(df_initial['InvoiceDate'])\n","\n","tab_info=pd.DataFrame(df_initial.dtypes).T.rename(index={0:'column type'})\n","tab_info=tab_info.append(pd.DataFrame(df_initial.isnull().sum()).T.rename(index={0:'null values (nb)'}))\n","tab_info=tab_info.append(pd.DataFrame(df_initial.isnull().sum()/df_initial.shape[0]*100).T.\n","                         rename(index={0:'null values (%)'}))\n","#print(tab_info)\n","display(tab_info)\n","#display(df_initial.head())\n","display(df_initial)\n","\n","df_initial.dropna(axis = 0, subset = ['CustomerID'], inplace = True)\n","\n","tab_info=pd.DataFrame(df_initial.dtypes).T.rename(index={0:'column type'})\n","tab_info=tab_info.append(pd.DataFrame(df_initial.isnull().sum()).T.rename(index={0:'null values (nb)'}))\n","tab_info=tab_info.append(pd.DataFrame(df_initial.isnull().sum()/df_initial.shape[0]*100).T.rename(index={0:'null values (%)'}))\n","df_initial.drop_duplicates(inplace = True)\n","\n","display(tab_info)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UMx_dPSSrNIh"},"outputs":[],"source":["### display number of orders per country\n","amount = df_initial.groupby('Country')['Country'].count().sort_values(ascending = False)\n","amount_df = pd.DataFrame(amount)\n","other_amt = amount_df[amount_df['Country']<5000].sum()\n","amount_gen = amount_df[amount_df['Country']>= 5000]\n","amount_gen.loc['Other'] = other_amt\n","\n","amount_gen.plot.pie(subplots = True, ylabel = \"\")\n","plt.title('Purchases by Country')\n","plt.legend(title = \"Country:\")\n","plt.show() \n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"aBiK23GwygD4"},"outputs":[],"source":["temp = df_initial.groupby(by=['CustomerID', 'InvoiceNo'], as_index=False)['InvoiceDate'].count()\n","nb_products_per_basket = temp.rename(columns = {'InvoiceDate':'Number of products'})\n","nb_products_per_basket[:10].sort_values('CustomerID')\n","\n","nb_products_per_basket['order_canceled'] = nb_products_per_basket['InvoiceNo'].apply(lambda x:int('C' in x))\n","n1 = nb_products_per_basket['order_canceled'].sum()\n","n2 = nb_products_per_basket.shape[0]\n","\n","df_cleaned = df_initial.copy(deep = True)\n","df_cleaned['QuantityCanceled'] = 0\n","\n","entry_to_remove = [] ; doubtfull_entry = []\n","\n","for index, col in  df_initial.iterrows():\n","    if (col['Quantity'] > 0) or col['Description'] == 'Discount': continue        \n","    df_test = df_initial[(df_initial['CustomerID'] == col['CustomerID']) &\n","                         (df_initial['StockCode']  == col['StockCode']) & \n","                         (df_initial['InvoiceDate'] < col['InvoiceDate']) & \n","                         (df_initial['Quantity']   > 0)].copy()\n","    # Cancelation WITHOUT counterpart\n","    if (df_test.shape[0] == 0): \n","        doubtfull_entry.append(index)\n","        # Cancelation WITH a counterpart\n","    elif (df_test.shape[0] == 1): \n","        index_order = df_test.index[0]\n","        df_cleaned.loc[index_order, 'QuantityCanceled'] = -col['Quantity']\n","        entry_to_remove.append(index)        \n","    # Various counterparts exist in orders: we delete the last one\n","    elif (df_test.shape[0] > 1): \n","        df_test.sort_index(axis=0 ,ascending=False, inplace = True)        \n","        for ind, val in df_test.iterrows():\n","            if val['Quantity'] < -col['Quantity']: continue\n","            df_cleaned.loc[ind, 'QuantityCanceled'] = -col['Quantity']\n","            entry_to_remove.append(index) \n","            break    \n","\n","#canceled order change 1 to canceled 0 to not canceled\n","cancel_prod = nb_products_per_basket.groupby('order_canceled')['order_canceled'].count().sort_values(ascending = False)\n","print('cancel prod: ', cancel_prod)\n","cancel_prod.plot.pie(subplots = True, ylabel = \"\", labels = ['Not Canceled', 'Canceled'])\n","#plt.pie(cancel_prod) \n","plt.legend(title = \"Purchase Cancelation:\")\n","plt.title(\"Orders Canceled\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FD-zvdz6tQP0"},"outputs":[],"source":["#part 1.5\n","df_cleaned.drop(entry_to_remove, axis = 0, inplace = True)\n","df_cleaned.drop(doubtfull_entry, axis = 0, inplace = True)\n","remaining_entries = df_cleaned[(df_cleaned['Quantity'] < 0) & (df_cleaned['StockCode'] != 'D')]\n","\n","#part 1.6\n","list_special_codes = df_cleaned[df_cleaned['StockCode'].str.contains('^[a-zA-Z]+', regex=True)]['StockCode'].unique()\n","list_special_codes\n","for code in list_special_codes:\n","    df_cleaned['TotalPrice'] = df_cleaned['UnitPrice'] * (df_cleaned['Quantity'] - df_cleaned['QuantityCanceled'])\n","df_cleaned.sort_values('CustomerID')[:5]\n","\n","#part 1.7\n","temp = df_cleaned.groupby(by=['CustomerID', 'InvoiceNo'], as_index=False)['TotalPrice'].sum()\n","basket_price = temp.rename(columns = {'TotalPrice':'Basket Price'})\n","df_cleaned['InvoiceDate_int'] = df_cleaned['InvoiceDate'].astype('int64')\n","temp = df_cleaned.groupby(by=['CustomerID', 'InvoiceNo'], as_index=False)['InvoiceDate_int'].mean()\n","df_cleaned.drop('InvoiceDate_int', axis = 1, inplace = True)\n","basket_price.loc[:, 'InvoiceDate'] = pd.to_datetime(temp['InvoiceDate_int'])\n","\n","\n","basket_price = basket_price[basket_price['Basket Price'] > 0]\n","#basket_price.sort_values('CustomerID')[:6]\n","\n","bp_data = basket_price['Basket Price']\n","plt.hist(bp_data, bins = np.arange(0,2000,100))\n","plt.title('Basket Price')\n","plt.xlabel('Price', fontsize = 15, color = 'k')\n","plt.ylabel('Frequency', fontsize = 15, color = 'k')\n","plt.xlim(xmin=0,xmax = 2000)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hkigjdCqYnRl"},"outputs":[],"source":["df_cleaned = pd.read_csv(data)\n","print(df_cleaned.head())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NSIN0HfWYQ2Z"},"outputs":[],"source":["is_noun = lambda pos: pos[:2] == 'NN'\n","\n","def keywords_inventory(dataframe, colonne = 'Description'):\n","    stemmer = nltk.stem.SnowballStemmer(\"english\")\n","    keywords_roots  = dict()  # collect the words / root\n","    keywords_select = dict()  # association: root <-> keyword\n","    category_keys   = []\n","    count_keywords  = dict()\n","    icount = 0\n","    for s in dataframe[colonne]:\n","        if pd.isnull(s): continue\n","        lines = s.lower()\n","        tokenized = nltk.word_tokenize(lines)\n","        nouns = [word for (word, pos) in nltk.pos_tag(tokenized) if is_noun(pos)] \n","        \n","        for t in nouns:\n","            t = t.lower() ; racine = stemmer.stem(t)\n","            if racine in keywords_roots:                \n","                keywords_roots[racine].add(t)\n","                count_keywords[racine] += 1                \n","            else:\n","                keywords_roots[racine] = {t}\n","                count_keywords[racine] = 1\n","        for s in keywords_roots.keys():\n","          if len(keywords_roots[s]) > 1:  \n","              min_length = 1000\n","              for k in keywords_roots[s]:\n","                  if len(k) < min_length:\n","                      clef = k\n","                      min_length = len(k)\n","\n","              category_keys.append(clef)\n","              keywords_select[s] = clef\n","          else:\n","              category_keys.append(list(keywords_roots[s])[0])\n","              keywords_select[s] = list(keywords_roots[s])[0]\n","                   \n","    print(\"Num of keywords in variable '{}': {}\".format(colonne,len(category_keys)))\n","    return category_keys, keywords_roots, keywords_select, count_keywords"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y6y1KpW9Y5z-"},"outputs":[],"source":["df_produits = pd.DataFrame(df_cleaned['Description'].unique()).rename(columns = {0:'Description'})\n","keywords, keywords_roots, keywords_select, count_keywords = keywords_inventory(df_produits)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"03TNBH9JXyo5"},"outputs":[],"source":["list_products = []\n","for k,v in count_keywords.items():\n","    word = keywords_select[k]\n","    if word in ['pink', 'blue', 'tag', 'green', 'orange']: continue\n","    if len(word) < 3 or v < 13: continue\n","    if ('+' in word) or ('/' in word): continue\n","    list_products.append([word, v])\n"," \n","list_products.sort(key = lambda x:x[1], reverse = True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eqdKjY2iBwDd"},"outputs":[],"source":["def makeWordCloud(frequencyList):\n","    '''\n","    input: a nested list, the first element in the inner list: a string presenting a product,\n","    the second element in the inner list: the frequency of the product\n","    output: show a word cloud\n","    '''\n","    words = dict()\n","    for innerList in frequencyList:\n","        words[innerList[0]] = innerList[1]\n","        \n","    wordcloud = WordCloud(width=1000,height=500, background_color='white', \n","                          max_words=150,relative_scaling=1,\n","                          color_func = None,\n","                          normalize_plurals=False)\n","    wordcloud.generate_from_frequencies(words)\n","    \n","    fig = plt.figure(1, figsize=(100,100))\n","    axis = fig.add_subplot(1,1,1)\n","    axis.imshow(wordcloud, interpolation=\"bilinear\")\n","    axis.axis('off')\n","\n","makeWordCloud(list_products)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lXJJbtudbOll"},"outputs":[],"source":["list_product = df_cleaned['Description'].unique()\n","X = pd.DataFrame()\n","for key, occurence in list_products:\n","    X.loc[:, key] = list(map(lambda x:int(key.upper() in x), list_product))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QR8OUZz7yKBd"},"outputs":[],"source":["threshold = [0, 1, 2, 3, 5, 10]\n","label_col = []\n","for i in range(len(threshold)):\n","    if i == len(threshold)-1:\n","        col = '.>{}'.format(threshold[i])\n","    else:\n","        col = '{}<.<{}'.format(threshold[i],threshold[i+1])\n","    label_col.append(col)\n","    X.loc[:, col] = 0\n","\n","for i, prod in enumerate(list_product):\n","    prix = df_cleaned[ df_cleaned['Description'] == prod]['UnitPrice'].mean()\n","    j = 0\n","    while prix > threshold[j]:\n","        j+=1\n","        if j == len(threshold): break\n","    X.loc[i, label_col[j-1]] = 1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BtnTWPe7aibF"},"outputs":[],"source":["silhouette_avg = -1\n","while silhouette_avg < 0.145:\n","    kmeans = KMeans(init='k-means++', n_clusters = 5, n_init=30)\n","    kmeans.fit(X)\n","    clusters = kmeans.predict(X)\n","    silhouette_avg = silhouette_score(X, clusters)\n","\n","corresp = dict()\n","for key, val in zip (list_product, clusters):\n","    corresp[key] = val \n","\n","df_cleaned['categ_product'] = df_cleaned.loc[:, 'Description'].map(corresp)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ri11gSqFf5wM"},"outputs":[],"source":["df_cleaned['QuantityCanceled'] = 0\n","\n","entry_to_remove = []\n","doubtfull_entry = []\n","\n","for index, col in  df_cleaned.iterrows():\n","    if (col['Quantity'] > 0) or col['Description'] == 'Discount': continue        \n","    df_test = df_cleaned[(df_cleaned['CustomerID'] == col['CustomerID']) &\n","                         (df_cleaned['StockCode']  == col['StockCode']) & \n","                         (df_cleaned['InvoiceDate'] < col['InvoiceDate']) & \n","                         (df_cleaned['Quantity']   > 0)].copy()\n","\n","    # Cancelation WITHOUT counterpart\n","    if (df_test.shape[0] == 0): \n","        doubtfull_entry.append(index)\n","\n","    # Cancelation WITH a counterpart\n","    elif (df_test.shape[0] == 1): \n","        index_order = df_test.index[0]\n","        df_cleaned.loc[index_order, 'QuantityCanceled'] = -col['Quantity']\n","        entry_to_remove.append(index)        \n","\n","    # Various counterparts exist in orders: we delete the last one\n","    elif (df_test.shape[0] > 1): \n","        df_test.sort_index(axis=0 ,ascending=False, inplace = True)        \n","        for ind, val in df_test.iterrows():\n","            if val['Quantity'] < -col['Quantity']: continue\n","            df_cleaned.loc[ind, 'QuantityCanceled'] = -col['Quantity']\n","            entry_to_remove.append(index) \n","            break   "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wIrNKWDUZWd1"},"outputs":[],"source":["for i in range(5):\n","    col = 'categ_{}'.format(i)        \n","    df_temp = df_cleaned[df_cleaned['categ_product'] == i]\n","    price_temp = df_temp['UnitPrice'] * (df_temp['Quantity'] - df_temp['QuantityCanceled'])\n","    price_temp = price_temp.apply(lambda x:x if x > 0 else 0)\n","    df_cleaned.loc[:, col] = price_temp\n","    df_cleaned[col].fillna(0, inplace = True)\n","\n","df_cleaned[['InvoiceNo', 'Description', 'categ_product', 'categ_0', 'categ_1', 'categ_2', 'categ_3','categ_4']][:5]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VzA6iCOflSnR"},"outputs":[],"source":["df_cleaned['TotalPrice'] = df_cleaned['UnitPrice'] * (df_cleaned['Quantity'] - df_cleaned['QuantityCanceled'])\n","df_cleaned.sort_values('CustomerID')[:5]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yxCsjgOKvQuu"},"outputs":[],"source":["temp = df_cleaned.groupby(by=['CustomerID', 'InvoiceNo'], as_index=False)['TotalPrice'].sum()\n","basket_price = temp.rename(columns = {'TotalPrice':'Basket Price'})\n","basket_price = basket_price[basket_price['Basket Price'] > 0]\n","basket_price.sort_values('CustomerID')[:6]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-50prHQ4vNPP"},"outputs":[],"source":["price_range = [0, 50, 100, 200, 500, 1000, 5000, 50000]\n","count_price = []\n","for i, price in enumerate(price_range):\n","    if i == 0: continue\n","    val = basket_price[(basket_price['Basket Price'] < price) &\n","                       (basket_price['Basket Price'] > price_range[i-1])]['Basket Price'].count()\n","    count_price.append(val)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xTC1p4M8dUA5"},"outputs":[],"source":["for i in range(5):\n","    col = 'categ_{}'.format(i) \n","    temp = df_cleaned.groupby(by=['CustomerID', 'InvoiceNo'], as_index=False)[col].sum()\n","    #print(temp)\n","    basket_price.loc[:, col] = temp[col]\n","\n","basket_price = basket_price[basket_price['Basket Price'] > 0]\n","basket_price.sort_values('CustomerID', ascending = True)[:5]"]},{"cell_type":"markdown","metadata":{"id":"U1Ki7Xmifp2f"},"source":["I group together the different entries that correspond to the same user. I thus determine the number of purchases made by the user, as well as the minimum, maximum, average amounts and the total amount spent during all the visits:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"51uwVTFEfkwX"},"outputs":[],"source":["transactions_per_user=basket_price.groupby(by=['CustomerID'])['Basket Price'].agg(['count','min','max','mean','sum'])\n","for i in range(5):\n","    col = 'categ_{}'.format(i)\n","    transactions_per_user.loc[:,col] = basket_price.groupby(by=['CustomerID'])[col].sum() /\\\n","                                            transactions_per_user['sum']*100\n","\n","transactions_per_user.reset_index(drop = False, inplace = True)\n","basket_price.groupby(by=['CustomerID'])['categ_0'].sum()\n","transactions_per_user.sort_values('CustomerID', ascending = True)[:5]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zPcEu3M_xJd6"},"outputs":[],"source":["from datetime import datetime\n","before = list(df_cleaned['InvoiceDate'])\n","after = [0] * len(before)\n","i = 0\n","for i in range(len(before)):\n","  after[i] = (datetime.fromisoformat(before[i]) - datetime(2010, 11, 30)).total_seconds()\n","df_cleaned['InvoiceDate_int'] = after\n","temp = df_cleaned.groupby(by=['CustomerID', 'InvoiceNo'], as_index=False)['InvoiceDate_int'].mean()\n","df_cleaned.drop('InvoiceDate_int', axis = 1, inplace = True)\n","basket_price.loc[:, 'InvoiceDate'] = pd.to_datetime(temp['InvoiceDate_int'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dD9_BUBidU2r"},"outputs":[],"source":["transactions_per_user=basket_price.groupby(by=['CustomerID'])['Basket Price'].agg(['count','min','max','mean','sum'])\n","for i in range(5):\n","    col = 'categ_{}'.format(i)\n","    transactions_per_user.loc[:,col] = basket_price.groupby(by=['CustomerID'])[col].sum() /\\\n","                                            transactions_per_user['sum']*100\n","\n","transactions_per_user.reset_index(drop = False, inplace = True)\n","basket_price.groupby(by=['CustomerID'])['categ_0'].sum()\n","transactions_per_user.sort_values('CustomerID', ascending = True)[:5]\n","last_date = basket_price['InvoiceDate'].max().date()\n","\n","first_registration = pd.DataFrame(basket_price.groupby(by=['CustomerID'])['InvoiceDate'].min())\n","last_purchase      = pd.DataFrame(basket_price.groupby(by=['CustomerID'])['InvoiceDate'].max())\n","\n","test  = first_registration.applymap(lambda x:(last_date - x.date()).days)\n","test2 = last_purchase.applymap(lambda x:(last_date - x.date()).days)\n","\n","transactions_per_user.loc[:, 'LastPurchase'] = test2.reset_index(drop = False)['InvoiceDate']\n","transactions_per_user.loc[:, 'FirstPurchase'] = test.reset_index(drop = False)['InvoiceDate']"]},{"cell_type":"markdown","metadata":{"id":"30Tfe_p9f8wq"},"source":["A customer category of particular interest is that of customers who make only one purchase. One of the objectives may be, for example, to target these customers in order to retain them. In part, I find that this type of customer represents 1/3 of the customers listed:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uo4t7_fgf2gi"},"outputs":[],"source":["n1 = transactions_per_user[transactions_per_user['count'] == 1].shape[0]\n","n2 = transactions_per_user.shape[0]\n","print(\"Proportion of customers who only made one purchase: {:<2}/{:<5} ({:<2.2f}%)\".format(n1,n2,n1/n2*100))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zVmaFUqhe_Jm"},"outputs":[],"source":["labels = 'Several times', 'Only Once'\n","sizes = [2838, 1489]\n","explode = (0, 0.1)  # only \"explode\" the 2nd slice (i.e. 'Hogs')\n","\n","fig1, ax1 = plt.subplots()\n","ax1.pie(sizes, explode=explode, labels=labels, autopct='%1.1f%%',\n","        shadow=True, startangle=90)\n","ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n","\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"CRB49pZwgk12"},"source":["The dataframe transactions_per_user contains a summary of all the commands that were made. Each entry in this dataframe corresponds to a particular client. I use this information to characterize the different types of customers and only keep a subset of variables:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x7wZvafad10f"},"outputs":[],"source":["list_cols = ['count','min','max','mean','categ_0','categ_1','categ_2','categ_3','categ_4']\n","#_____________________________________________________________\n","selected_customers = transactions_per_user.copy(deep = True)\n","X = selected_customers[list_cols]"]},{"cell_type":"markdown","metadata":{"id":"_J4KSOskgpl_"},"source":[" create a matrix where these data are standardized:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9AO99t8Bd9R-"},"outputs":[],"source":["scaler = StandardScaler()\n","scaler.fit(X)\n","scaled_X = scaler.transform(X)\n","pca = PCA(n_components=6)\n","pca.fit(scaled_X)\n","n_clusters = 11\n","\n","kmeans = KMeans(init='k-means++', n_clusters = n_clusters, n_init=100)\n","kmeans.fit(scaled_X)\n","clusters_clients = kmeans.predict(scaled_X)\n","selected_customers.loc[:, 'cluster'] = clusters_clients"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RNzTT5IOehpD"},"outputs":[],"source":["merged_df = pd.DataFrame()\n","for i in range(n_clusters):\n","    test = pd.DataFrame(selected_customers[selected_customers['cluster'] == i].mean())\n","    test = test.T.set_index('cluster', drop = True)\n","    test['size'] = selected_customers[selected_customers['cluster'] == i].shape[0]\n","    merged_df = pd.concat([merged_df, test])\n","#_____________________________________________________\n","merged_df.drop('CustomerID', axis = 1, inplace = True)\n","print('number of customers:', merged_df['size'].sum())\n","\n","merged_df = merged_df.sort_values('sum')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UuB2kk4Ke44v"},"outputs":[],"source":["def _scale_data(data, ranges):\n","    (x1, x2) = ranges[0]\n","    d = data[0]\n","    return [(d - y1) / (y2 - y1) * (x2 - x1) + x1 for d, (y1, y2) in zip(data, ranges)]"]},{"cell_type":"markdown","metadata":{"id":"IH7z8crFlvXA"},"source":["I created a representation of the different morphotypes. To do this, I define a class to create \"Radar Charts\". (which has been adapted from this [kernel](https://www.kaggle.com/yassineghouzam/don-t-know-why-employees-leave%20-read-this))\n","\n","This allows us to have a global view of the content of each cluster:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jF0eIYaJeqaI"},"outputs":[],"source":["class RadarChart():\n","    def __init__(self, fig, location, sizes, variables, ranges, n_ordinate_levels = 6):\n","\n","        angles = np.arange(0, 360, 360./len(variables))\n","\n","        ix, iy = location[:] ; size_x, size_y = sizes[:]\n","        \n","        axes = [fig.add_axes([ix, iy, size_x, size_y], polar = True, \n","        label = \"axes{}\".format(i)) for i in range(len(variables))]\n","\n","        _, text = axes[0].set_thetagrids(angles, labels = variables)\n","        \n","        for txt, angle in zip(text, angles):\n","            if angle > -1 and angle < 181:\n","                txt.set_rotation(angle - 90)\n","            else:\n","                txt.set_rotation(angle - 270)\n","        \n","        for ax in axes[1:]:\n","            ax.patch.set_visible(False)\n","            ax.xaxis.set_visible(False)\n","            ax.grid(\"off\")\n","        \n","        for i, ax in enumerate(axes):\n","            grid = np.linspace(*ranges[i],num = n_ordinate_levels)\n","            grid_label = [\"\"]+[\"{:.0f}\".format(x) for x in grid[1:-1]]\n","            ax.set_rgrids(grid, labels = grid_label, angle = angles[i])\n","            ax.set_ylim(*ranges[i])\n","        \n","        self.angle = np.deg2rad(np.r_[angles, angles[0]])\n","        self.ranges = ranges\n","        self.ax = axes[0]\n","                \n","    def plot(self, data, *args, **kw):\n","        sdata = _scale_data(data, self.ranges)\n","        self.ax.plot(self.angle, np.r_[sdata, sdata[0]], *args, **kw)\n","\n","    def fill(self, data, *args, **kw):\n","        sdata = _scale_data(data, self.ranges)\n","        self.ax.fill(self.angle, np.r_[sdata, sdata[0]], *args, **kw)\n","\n","    def legend(self, *args, **kw):\n","        self.ax.legend(*args, **kw)\n","        \n","    def title(self, title, *args, **kw):\n","        self.ax.text(0.9, 1, title, transform = self.ax.transAxes, *args, **kw)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6JnJyH6LeqJ1"},"outputs":[],"source":["fig = plt.figure(figsize=(16,12))\n","\n","attributes = ['count', 'mean', 'sum', 'categ_0', 'categ_1', 'categ_2', 'categ_3', 'categ_4']\n","ranges = [[0.01, 10], [0.01, 1500], [0.01, 10000], [0.01, 75], [0.01, 75], [0.01, 75], [0.01, 75], [0.01, 75]]\n","index  = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n","\n","n_clusters = 11\n","n_groups = n_clusters \n","i_cols = 3\n","i_rows = n_groups//i_cols\n","size_x, size_y = (1/i_cols), (1/i_rows)\n","\n","for ind in range(n_clusters):\n","    ix = ind%3 ; iy = i_rows - ind//3\n","    pos_x = ix*(size_x + 0.05) ; pos_y = iy*(size_y + 0.05)            \n","    location = [pos_x, pos_y]  ; sizes = [size_x, size_y] \n","    #______________________________________________________\n","    data = np.array(merged_df.loc[index[ind], attributes]) +1   \n","    radar = RadarChart(fig, location, sizes, attributes, ranges)\n","    radar.plot(data, color = 'b', linewidth=2.0)\n","    radar.fill(data, alpha = 0.2, color = 'b')\n","    radar.title(title = 'cluster {}'.format(index[ind]+1), color = 'r')\n","    ind += 1 "]},{"cell_type":"markdown","metadata":{"id":"7vhzcXc-l-ij"},"source":["It can be seen, for example, that the first 5 clusters correspond to a strong preponderance of purchases in a particular category of products. Other clusters will differ from basket averages ( mean ), the total sum spent by the clients ( sum ) or the total number of visits made ( count )."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eMGZGQ4KhLlF"},"outputs":[],"source":["import plotly.express as px\n","\n","prices = df_cleaned[['InvoiceDate', 'Country', 'UnitPrice']]\n","countries_ = [c for c in prices['Country'].unique()]\n","countries = countries_[1:]\n","prices['InvoiceDate'] = prices['InvoiceDate'].str[:10]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cl8hIjY55t8J"},"outputs":[],"source":["import itertools\n","\n","mapp = dict()\n","for i in range(len(countries_)):\n","  tmp = prices.loc[prices['Country'] == countries_[i]]\n","  mapp[countries_[i]] = len(tmp)\n","\n","\n","mapp = dict(sorted(mapp.items(), key=lambda item: item[1], reverse=True))\n","top10 = list(mapp.items())[:10]\n","top10 = [k for k,v in top10]\n","top10"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Clt-F9mO5l2E"},"outputs":[],"source":["group_country = prices.groupby(['Country', 'InvoiceDate']).sum()\n","df = pd.DataFrame(group_country, columns = ['UnitPrice'], index= group_country.index)\n","df.reset_index(inplace=True)\n","\n","M = df.loc[df['Country'] == 'United Kingdom']\n","for i in countries:\n","  tmp = df.loc[df['Country'] == i]\n","  tmp = tmp.drop(['Country'], axis=1)\n","  M = pd.merge(M, tmp, how=\"left\", on=[\"InvoiceDate\"])\n","\n","M = M.drop(['Country'], axis=1)\n","M.columns = ['InvoiceDate','United Kingdom'] + countries\n","M.columns.name = 'country'\n","M = M.set_index('InvoiceDate')\n","M.head()\n","M1 = M"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jUCkBHfLQKcE"},"outputs":[],"source":["fig = px.bar(M, x=M.index, y=\"United Kingdom\")\n","fig.show()\n","fig = px.bar(M, x=M.index, y=\"Germany\")\n","fig.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MO3-ZeVdRYwu"},"outputs":[],"source":["fig = px.area(M[top10], facet_col=\"country\", facet_col_wrap=2)\n","fig.show()"]},{"cell_type":"markdown","metadata":{"id":"-8zmX7ZlSZuR"},"source":["Do the same thing on trading quantity."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xhswPFYaR_BJ"},"outputs":[],"source":["quantity = df_cleaned[['InvoiceDate', 'Country', 'Quantity']]\n","# add up all amount of items\n","quantity['InvoiceDate'] = quantity['InvoiceDate'].str[:10]\n","group_quantity = quantity.groupby(['Country', 'InvoiceDate'])['Quantity'].count()\n","df = pd.DataFrame(group_quantity, columns = ['Quantity'], index= group_quantity.index)\n","df.reset_index(inplace=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kZ6KLbmhRVO-"},"outputs":[],"source":["M = df.loc[df['Country'] == 'United Kingdom']\n","for i in countries:\n","  tmp = df.loc[df['Country'] == i]\n","  tmp = tmp.drop(['Country'], axis=1)\n","  M = pd.merge(M, tmp, how=\"left\", on=[\"InvoiceDate\"])\n","\n","M = M.drop(['Country'], axis=1)\n","M.columns = ['Quantity','United Kingdom'] + countries\n","M.columns.name = 'country'\n","M = M.set_index('Quantity')\n","M2 = M\n","M.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MRk1FjbZameJ"},"outputs":[],"source":["fig = px.bar(M, x=M.index, y=\"United Kingdom\")\n","fig.show()\n","fig = px.bar(M, x=M.index, y=\"Germany\")\n","fig.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3o4MdPUWbSoU"},"outputs":[],"source":["fig = px.area(M[top10], facet_col=\"country\", facet_col_wrap=2)\n","fig.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hhdKLsLqchrE"},"outputs":[],"source":["import plotly.express as px\n","\n","M1.head()\n","\n","alpha_map = {'France': 'FRA', 'United Kingdom': 'GBR', 'Australia': 'AUS', 'Netherlands': 'NLD', 'Germany': 'DEU',\n","             'Norway': 'NOR', 'EIRE': 'IRL', 'Switzerland': 'CHE', 'Spain': 'ESP' ,'Poland': 'POL', 'Portugal': 'PRT', 'Italy': 'ITA',\n","             'Belgium': 'BEL', 'Lithuania': 'LTU', 'Japan': 'JPN', 'Iceland': 'ISL', 'Denmark': 'DNK', 'Channel Islands': -1,\n","             'Cyprus': 'CYP', 'Sweden': 'SWE', 'Austria': 'AUT', 'Israel': 'ISR', 'Finland': 'FIN', 'Greece': 'GRC', 'Singapore': 'SGP',\n","             'Lebanon': 'LBN', 'United Arab Emirates': 'ARE', 'Saudi Arabia': 'SAU', 'Czech Republic': 'CZE', 'Canada': 'CAN',\n","             'Unspecified': -1, 'Brazil': 'BRA', 'USA': 'USA', 'Bahrain': 'BHR', 'European Community': -1, 'Malta':'MLT', 'RSA': -1}\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6B8Uo9d3iamB"},"outputs":[],"source":["continent_map = {'United Kingdom': 'Europe', 'France': 'Europe', 'Australia': 'Asia', 'Netherlands': 'Europe', 'Germany': 'Europe',\n","                'Norway': 'Europe',  'EIRE': 'Europe', 'Switzerland': 'Europe', 'Spain': 'Europe', 'Poland': 'Europe', 'Portugal': 'Europe',\n","                'Italy': 'Europe', 'Belgium': 'Europe', 'Lithuania': 'Europe', 'Japan': 'Asia', 'Iceland': 'Europe', 'Channel Islands': -1, \n","                'Denmark': 'Europe', 'Cyprus': 'Europe', 'Sweden': 'Europe', 'Austria': 'Europe', 'Israel': 'Asia', 'Finland': 'Europe', 'Greece': 'Europe',\n","                'Singapore': 'Asia', 'Lebanon': 'Asia', 'United Arab Emirates': 'Asia','Saudi Arabia': 'Asia', 'Czech Republic': 'Europe', 'Canada': 'North America',\n","                'Unspecified': -1, 'Brazil': 'South America', 'USA': 'North America', 'European Community': -1, 'Bahrain': 'Asia', 'Malta': 'Europe', 'RSA': -1}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"drVYthFIkhtz"},"outputs":[],"source":["label_alpha = pd.DataFrame([alpha_map[countries[i]] for i in range(len(countries))])\n","label_con = pd.DataFrame([continent_map[countries[i]] for i in range(len(countries))])\n","M2['iso_alpha'] = label_alpha\n","M2['continent'] = label_con"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P8eT2T11k39F"},"outputs":[],"source":["Q = df_cleaned[['Country', 'Quantity']]\n","QQ = pd.DataFrame(Q.groupby('Country')['Quantity'].sum())\n","QQ = pd.DataFrame(QQ, columns = ['Quantity'], index = QQ.index)\n","QQ.reset_index(inplace=True)\n","QQ['iso_alpha'] = pd.DataFrame([alpha_map[l] for l in QQ['Country']])\n","QQ['continent'] = pd.DataFrame([continent_map[l] for l in QQ['Country']])\n","QQ.drop(QQ[QQ['iso_alpha'] == -1].index, inplace = True)\n","QQ.drop(QQ[QQ['continent'] == -1].index, inplace = True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OgKarIxFd-22"},"outputs":[],"source":["fig = px.scatter_geo(QQ, locations=\"iso_alpha\", color=\"continent\",\n","                     hover_name=\"Country\", size=\"Quantity\", projection='natural earth')\n","fig.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C2ywPeXhiSWP"},"outputs":[],"source":["QQ.loc[QQ['Country'] != 'United Kingdom', 'country'] = 'Other countries'\n","QQ.loc[QQ['Country'] == 'United Kingdom', 'country'] = 'United Kingdom'\n","fig = px.pie(QQ, values='Quantity', names='country', title='Quantity of Buying in different Countries - UK v.s. Others')\n","fig.show()\n","\n","# we already know UK has the largest ammount of buying, we want to see other countries so we drop it, otherwise the plot would be hard to interpret.\n","QQ_ = QQ.drop(labels=35, axis=0)\n","fig = px.pie(QQ_, values='Quantity', names='Country', title='Quantity of Buying in different Countries')\n","fig.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P50f34JbyosN"},"outputs":[],"source":[""]}],"metadata":{"colab":{"collapsed_sections":[],"name":"visualization_part.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}